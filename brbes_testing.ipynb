{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "from glob import glob\n",
    "from itertools import product\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from interval import interval, inf\n",
    "\n",
    "from brb.attr_input import AttributeInput\n",
    "from brb.brb import csv2BRB"
   ]
  },
  {
   "source": [
    "# Read the Rule Base and create the Expert System"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename =  'csv_HPO_BeliefRuleBase_wKO_v15.csv_RefVals_AntImp-1Mglobscaled.csv'\n",
    "filepath = os.path.join('csv_rulebases', filename)\n",
    "\n",
    "assert os.path.exists(filepath), \"rulebase doesn't exist\"\n",
    "\n",
    "# create model from rules.csv\n",
    "model = csv2BRB(filepath,\n",
    "                #'csv_rulebases/csv_ML_BeliefRuleBase_v5.csv_spec_refvals*ant_imp--scaled.csv',\n",
    "                #'csv_rulebases/csv_HPO_BeliefRuleBase_v11.csv_spec_refvals*ant_imp--scaled.csv',\n",
    "                antecedents_prefix='A_',\n",
    "                consequents_prefix='D_',\n",
    "                deltas_prefix='del_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['A_UR: quality demands',\n",
       " \"A_User's programming ability\",\n",
       " 'A_UR: need for model transparency',\n",
       " 'A_UR: Availability of a well documented library',\n",
       " 'A_UR: Computer operating system',\n",
       " 'A_Hardware: Number of workers/kernels for parallel computing',\n",
       " 'A_Production application area',\n",
       " 'A_Number of maximum function evaluations/ trials budget',\n",
       " 'A_Running time per trial [s]',\n",
       " 'A_Total Computing Time [s]',\n",
       " 'A_Machine Learning Algorithm',\n",
       " 'A_Obtainability of good approximate',\n",
       " 'A_Supports parallel evaluations',\n",
       " 'A_Dimensionality of HPs',\n",
       " 'A_Conditional HP space',\n",
       " 'A_HP datatypes',\n",
       " 'A_Availability of a warm-start HP configuration',\n",
       " 'A_Obtainability of gradients',\n",
       " 'A_Input Data',\n",
       " 'A_#Instances training dataset',\n",
       " 'A_Ratio training to test dataset',\n",
       " 'A_Noise in dataset',\n",
       " 'A_Training Technique',\n",
       " 'A_ML task',\n",
       " 'A_Detailed ML task']"
      ]
     },
     "metadata": {},
     "execution_count": 134
    }
   ],
   "source": [
    "model.U_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['Synthetic Function',\n",
       " 'Deep Neural Net',\n",
       " 'Decision Tree',\n",
       " 'Convolutional Neural Net',\n",
       " 'Gradient Boosting Machine',\n",
       " 'Multilayer Perceptron',\n",
       " 'Logistic Regression',\n",
       " 'XGBoost',\n",
       " 'Latent Dirichlet Allocation (HPOlib)',\n",
       " 'Random Forest',\n",
       " 'Support Vector Machine',\n",
       " 'LSTM']"
      ]
     },
     "metadata": {},
     "execution_count": 135
    }
   ],
   "source": [
    "model.U[10].referential_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Max's results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['Trial-ID', 'HPO-library', 'HPO-method', 'ML-algorithm', 'Runs',\n",
       "       'Evaluations', 'Workers', 'GPU', 'Warmstart', 'Wall clock time [s]',\n",
       "       't outperform default [s]', 'Mean (final validation loss)',\n",
       "       'Validation baseline', 'Area under curve (AUC)',\n",
       "       'Mean (final test loss)', 'Test loss ratio (default / best)',\n",
       "       'Test baseline', 'Interquartile range (final test loss)',\n",
       "       't best configuration [s]', 'Generalization error',\n",
       "       'Evaluations for best configuration', 'Crashes', '# training instances',\n",
       "       '# training features', '# test instances', '# test features', 'dataset',\n",
       "       '# cont. HPs', '# int. HPs', '# cat. HPs', 'loss_metric'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 136
    }
   ],
   "source": [
    "dataset = 'scania'  # 'turbofan', 'scania', 'sensor\n",
    "ml_task = 'Binary Classification'  # 'Regression', 'Binary Classification', 'Multiclass Classification'\n",
    "\n",
    "file_name = 'expanded_metrics_' + dataset + '.csv'\n",
    "maxr_fpath = os.path.join('max_results', file_name)\n",
    "\n",
    "maxr = pd.read_csv(maxr_fpath, index_col=0)\n",
    "\n",
    "maxr.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                               Trial-ID HPO-library HPO-method  \\\n",
       "0  e3c90f48-3ecb-426a-94d1-769dd6794e16        robo  Bohamiann   \n",
       "1  e3c90f48-3ecb-426a-94d1-769dd6794e16        robo  Bohamiann   \n",
       "2  a53df618-2580-48d5-b647-e741a08d73cc  hpbandster       BOHB   \n",
       "3  a53df618-2580-48d5-b647-e741a08d73cc  hpbandster       BOHB   \n",
       "4  65f01428-62bb-4163-b4bb-3e8aba31aa52      optuna     CMA-ES   \n",
       "\n",
       "        ML-algorithm  Runs  Evaluations  Workers    GPU  Warmstart  \\\n",
       "0  AdaBoostRegressor     5        200.0        1  False      False   \n",
       "1  AdaBoostRegressor     5          NaN        1  False      False   \n",
       "2  AdaBoostRegressor    10        200.0        1  False      False   \n",
       "3  AdaBoostRegressor    10          NaN        1  False      False   \n",
       "4  AdaBoostRegressor    10        200.0        1  False      False   \n",
       "\n",
       "   Wall clock time [s]  ...  Crashes  # training instances  \\\n",
       "0           415.614018  ...        0                 16584   \n",
       "1            40.000000  ...        0                 16584   \n",
       "2           415.614018  ...        0                 16584   \n",
       "3            40.000000  ...        0                 16584   \n",
       "4           415.614018  ...        0                 16584   \n",
       "\n",
       "   # training features  # test instances  # test features   dataset  \\\n",
       "0                   17              4147               17  turbofan   \n",
       "1                   17              4147               17  turbofan   \n",
       "2                   17              4147               17  turbofan   \n",
       "3                   17              4147               17  turbofan   \n",
       "4                   17              4147               17  turbofan   \n",
       "\n",
       "   # cont. HPs  # int. HPs  # cat. HPs  loss_metric  \n",
       "0            1           2           1     RUL-loss  \n",
       "1            1           2           1     RUL-loss  \n",
       "2            1           2           1     RUL-loss  \n",
       "3            1           2           1     RUL-loss  \n",
       "4            1           2           1     RUL-loss  \n",
       "\n",
       "[5 rows x 31 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Trial-ID</th>\n      <th>HPO-library</th>\n      <th>HPO-method</th>\n      <th>ML-algorithm</th>\n      <th>Runs</th>\n      <th>Evaluations</th>\n      <th>Workers</th>\n      <th>GPU</th>\n      <th>Warmstart</th>\n      <th>Wall clock time [s]</th>\n      <th>...</th>\n      <th>Crashes</th>\n      <th># training instances</th>\n      <th># training features</th>\n      <th># test instances</th>\n      <th># test features</th>\n      <th>dataset</th>\n      <th># cont. HPs</th>\n      <th># int. HPs</th>\n      <th># cat. HPs</th>\n      <th>loss_metric</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>e3c90f48-3ecb-426a-94d1-769dd6794e16</td>\n      <td>robo</td>\n      <td>Bohamiann</td>\n      <td>AdaBoostRegressor</td>\n      <td>5</td>\n      <td>200.0</td>\n      <td>1</td>\n      <td>False</td>\n      <td>False</td>\n      <td>415.614018</td>\n      <td>...</td>\n      <td>0</td>\n      <td>16584</td>\n      <td>17</td>\n      <td>4147</td>\n      <td>17</td>\n      <td>turbofan</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>RUL-loss</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>e3c90f48-3ecb-426a-94d1-769dd6794e16</td>\n      <td>robo</td>\n      <td>Bohamiann</td>\n      <td>AdaBoostRegressor</td>\n      <td>5</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>False</td>\n      <td>False</td>\n      <td>40.000000</td>\n      <td>...</td>\n      <td>0</td>\n      <td>16584</td>\n      <td>17</td>\n      <td>4147</td>\n      <td>17</td>\n      <td>turbofan</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>RUL-loss</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>a53df618-2580-48d5-b647-e741a08d73cc</td>\n      <td>hpbandster</td>\n      <td>BOHB</td>\n      <td>AdaBoostRegressor</td>\n      <td>10</td>\n      <td>200.0</td>\n      <td>1</td>\n      <td>False</td>\n      <td>False</td>\n      <td>415.614018</td>\n      <td>...</td>\n      <td>0</td>\n      <td>16584</td>\n      <td>17</td>\n      <td>4147</td>\n      <td>17</td>\n      <td>turbofan</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>RUL-loss</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>a53df618-2580-48d5-b647-e741a08d73cc</td>\n      <td>hpbandster</td>\n      <td>BOHB</td>\n      <td>AdaBoostRegressor</td>\n      <td>10</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>False</td>\n      <td>False</td>\n      <td>40.000000</td>\n      <td>...</td>\n      <td>0</td>\n      <td>16584</td>\n      <td>17</td>\n      <td>4147</td>\n      <td>17</td>\n      <td>turbofan</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>RUL-loss</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>65f01428-62bb-4163-b4bb-3e8aba31aa52</td>\n      <td>optuna</td>\n      <td>CMA-ES</td>\n      <td>AdaBoostRegressor</td>\n      <td>10</td>\n      <td>200.0</td>\n      <td>1</td>\n      <td>False</td>\n      <td>False</td>\n      <td>415.614018</td>\n      <td>...</td>\n      <td>0</td>\n      <td>16584</td>\n      <td>17</td>\n      <td>4147</td>\n      <td>17</td>\n      <td>turbofan</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>RUL-loss</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 31 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 137
    }
   ],
   "source": [
    "maxr.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input generation for the Expert System (Use Cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping between BRB and BM notation\n",
    "\n",
    "# Map ML algorithms: BRB -> BM\n",
    "# TODO: Needs to be expanded to include classification algorithms\n",
    "\n",
    "if ml_task == 'Regression':\n",
    "    \n",
    "    ml_brb2bm_map = {\n",
    "        'Ada Boost': 'AdaBoostRegressor',\n",
    "        'Decision Tree': 'DecisionTreeRegressor',\n",
    "        'Support Vector Machine': 'SVR',\n",
    "        'KNN': 'KNNRegressor',\n",
    "        'Gradient Boosting Machine': 'LGBMRegressor',\n",
    "        'Random Forest': 'RandomForestRegressor',\n",
    "        'XGBoost': 'XGBoostRegressor',\n",
    "        'ElasticNet': 'ElasticNet',\n",
    "        'Multilayer Perceptron': 'KerasRegressor'\n",
    "    }\n",
    "\n",
    "elif ml_task == 'Binary Classification' or ml_task == 'Multiclass Classification':\n",
    "\n",
    "    ml_brb2bm_map = {\n",
    "        'Ada Boost': 'AdaBoostClassifier',\n",
    "        'Decision Tree': 'DecisionTreeClassifier',\n",
    "        'Support Vector Machine': 'SVC',\n",
    "        'KNN': 'KNNClassifier',\n",
    "        'Gradient Boosting Machine': 'LGBMClassifier',\n",
    "        'Random Forest': 'RandomForestClassifier',\n",
    "        'XGBoost': 'XGBoostClassifier',\n",
    "        'Logistic Regression': 'LogisticRegression',\n",
    "        'Multilayer Perceptron': 'KerasClassifier',\n",
    "        'NaiveBayes': 'NaiveBayes'\n",
    "    }\n",
    "\n",
    "else:\n",
    "    raise Exception('Unknown ML task!')\n",
    "\n",
    "# Map ML algorithms: BM -> BRB\n",
    "ml_bm2brb_map = {v: k for k, v in ml_brb2bm_map.items()}\n",
    "\n",
    "# Map HPO techniques: BRB -> BM\n",
    "hpo_brb2bm_map = {\n",
    "    'BOHAMIANN': 'Bohamiann',\n",
    "    'BOHB': 'BOHB',\n",
    "    'CMA-ES': 'CMA-ES',\n",
    "    'FABOLAS': 'Fabolas',\n",
    "    'GPBO': 'GPBO',\n",
    "    'HB': 'Hyperband',\n",
    "    'Random Search': 'RandomSearch',\n",
    "    'SMAC': 'SMAC',\n",
    "    'TPE': 'TPE',\n",
    "    'Default Values': 'Default Values'\n",
    "}\n",
    "\n",
    "# Map HPO techniques: BM -> BRB\n",
    "hpo_bm2brb_map = {v: k for k, v in hpo_brb2bm_map.items()}\n",
    "\n",
    "# Map warm tart notation: BRB -> BM\n",
    "wst_brb2bm_map = {'yes': True, 'no': False}\n",
    "\n",
    "wst_bm2brb_map = {v: k for k, v in wst_brb2bm_map.items()}\n",
    "\n",
    "# Map ML algorithms with HP data types\n",
    "bmalgo2paratype_map = {\n",
    "    'RandomForestRegressor': '[continuous, discrete, nominal]',\n",
    "    'RandomForestClassifier': '[continuous, discrete, nominal]',\n",
    "    'MLPRegressor': '[discrete, nominal]',\n",
    "    'MLPClassifier': '[discrete, nominal]',\n",
    "    'SVR': '[continuous, nominal]',\n",
    "    'SVC': '[continuous, nominal]',\n",
    "    'KerasRegressor': '[continuous, discrete, nominal]',\n",
    "    'KerasClassifier': '[continuous, discrete, nominal]',\n",
    "    'XGBoostClassifier': '[continuous, discrete, nominal]',\n",
    "    'XGBoostRegressor': '[continuous, discrete, nominal]',\n",
    "    'AdaBoostRegressor': '[continuous, discrete, nominal]',\n",
    "    'AdaBoostClassifier': '[continuous, discrete, nominal]',\n",
    "    'DecisionTreeRegressor': '[continuous, discrete]',\n",
    "    'DecisionTreeClassifier': '[continuous, discrete]',\n",
    "    'LinearRegression': '[nominal]',\n",
    "    'KNNRegressor': '[discrete, nominal]',\n",
    "    'KNNClassifier': '[discrete, nominal]',\n",
    "    'LGBMRegressor': '[continuous, discrete]',\n",
    "    'LGBMClassifier': '[continuous, discrete]',\n",
    "    'LogisticRegression': '[continuous, discrete, nominal]',\n",
    "    'ElasticNet': '[continuous, discrete, nominal]',\n",
    "    'NaiveBayes': '[continuous]'}\n",
    "\n",
    "# Map ML algorithms with conditional / non-conditional HPs\n",
    "bmalgo2cond_map = {\n",
    "    'RandomForestRegressor': 'no',\n",
    "    'RandomForestClassifier': 'no',\n",
    "    'MLPRegressor': 'no',\n",
    "    'MLPClassifier': 'no',\n",
    "    'SVR': 'no',\n",
    "    'SVC': 'no',\n",
    "    'KerasRegressor': 'no',\n",
    "    'KerasClassifier': 'no',\n",
    "    'XGBoostClassifier': 'yes',\n",
    "    'XGBoostRegressor': 'yes',\n",
    "    'AdaBoostRegressor': 'no',\n",
    "    'AdaBoostClassifier': 'no',\n",
    "    'DecisionTreeRegressor': 'no',\n",
    "    'DecisionTreeClassifier': 'no',\n",
    "    'LinearRegression': 'no',\n",
    "    'KNNRegressor': 'no',\n",
    "    'KNNClassifier': 'no',\n",
    "    'LGBMRegressor': 'no',\n",
    "    'LGBMClassifier': 'no',\n",
    "    'LogisticRegression': 'no',\n",
    "    'ElasticNet': 'no',\n",
    "    'NaiveBayes': 'no'}\n",
    "\n",
    "# Map dataset information with some (constant) antecedents\n",
    "datset2constant_map = {\n",
    "    'turbofan': {\n",
    "        \"Detailed ML task\": 'Prediction of Remaining Useful Lifetime',\n",
    "        \"Production application area\": 'Predictive Maintenance',\n",
    "        \"Input Data\": 'Tabular Data',\n",
    "        \"Ratio training to test dataset\": 4,\n",
    "        \"ML task\": 'Regression'\n",
    "        },\n",
    "    'scania': {\n",
    "        \"Detailed ML task\": 'Prediction of Part Failure',\n",
    "        \"Production application area\": 'Predictive Maintenance',\n",
    "        \"Input Data\": 'Tabular Data',\n",
    "        \"Ratio training to test dataset\": 4,\n",
    "        \"ML task\": 'Binary Classification'\n",
    "    },\n",
    "    'sensor': {\n",
    "        \"Detailed ML task\": 'Prediction of Product Quality',\n",
    "        \"Production application area\": 'Predictive Quality',\n",
    "        \"Input Data\": 'Tabular Data',\n",
    "        \"Ratio training to test dataset\": 4,\n",
    "        \"ML task\": 'Multiclass Classification'\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame to store the use cases for the evaluation of the BRBES (each row corresponds to a single use case)\n",
    "df_use_case = pd.DataFrame([])\n",
    "df_use_case['Machine Learning Algorithm'] = maxr['ML-algorithm'].map(ml_bm2brb_map)\n",
    "df_use_case['Hardware: Number of workers/kernels for parallel computing'] = maxr['Workers']\n",
    "df_use_case['Availability of a warm-start HP configuration'] = maxr['Warmstart'].map(wst_bm2brb_map)\n",
    "df_use_case['Number of maximum function evaluations/ trials budget'] = maxr['Evaluations']\n",
    "# df_use_case['Running time per trial [s]'] = [interval[0, 30]] * len(maxr['ML-algorithm']) # TODO: Calculation necessary\n",
    "df_use_case['Running time per trial [s]'] = maxr['Wall clock time [s]'] / maxr['Evaluations']\n",
    "df_use_case['Total Computing Time [s]'] = maxr['Wall clock time [s]']\n",
    "df_use_case['Dimensionality of HPs'] = maxr['# cont. HPs'] + maxr['# int. HPs'] + maxr['# cat. HPs']\n",
    "df_use_case['HP datatypes'] = maxr['ML-algorithm'].map(bmalgo2paratype_map)\n",
    "df_use_case['Conditional HP space'] = maxr['ML-algorithm'].map(bmalgo2cond_map)\n",
    "df_use_case[\"Detailed ML task\"] = datset2constant_map[dataset][\"Detailed ML task\"]\n",
    "df_use_case[\"Production application area\"] = datset2constant_map[dataset][\"Production application area\"]\n",
    "df_use_case['Input Data'] = datset2constant_map[dataset][\"Input Data\"]\n",
    "df_use_case['#Instances training dataset'] = maxr['# training instances']\n",
    "df_use_case['Ratio training to test dataset'] = datset2constant_map[dataset][\"Ratio training to test dataset\"]\n",
    "df_use_case['ML task'] = datset2constant_map[dataset][\"ML task\"]\n",
    "\n",
    "# fixed antecedents (cannot yet be derived from the metrics .csv file)\n",
    "df_use_case[\"UR: quality demands\"] = 'high'\n",
    "df_use_case[\"User's programming ability\"] = ''\n",
    "df_use_case[\"UR: Computer operating system\"] = 'Linux'\n",
    "df_use_case[\"Obtainability of good approximate\"] = [{'yes':0.5, 'no':0.5}] * len(maxr['ML-algorithm'])\n",
    "df_use_case[\"Supports parallel evaluations\"] = [{'yes':0.5, 'no':0.5}] * len(maxr['ML-algorithm'])\n",
    "df_use_case[\"Obtainability of gradients\"] = [{'yes':0.5, 'no':0.5}] * len(maxr['ML-algorithm'])\n",
    "df_use_case[\"Noise in dataset\"] = [{'yes':0.5, 'no':0.5}] * len(maxr['ML-algorithm'])\n",
    "df_use_case[\"Training Technique\"] = \"Offline\"\n",
    "df_use_case[\"UR: need for model transparency\"] = ''\n",
    "df_use_case[\"UR: Availability of a well documented library\"] = ''\n",
    "\n",
    "\n",
    "# TODO: Iterate over quality demands, robustness, UR antecedents, etc. to create new use cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicate use cases\n",
    "col_subset = df_use_case.columns\n",
    "col_subset = col_subset[:-7]\n",
    "df_use_case.drop_duplicates(subset=col_subset, inplace=True, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  Machine Learning Algorithm  \\\n",
       "0                  Ada Boost   \n",
       "1                  Ada Boost   \n",
       "2                  Ada Boost   \n",
       "3                  Ada Boost   \n",
       "4                  Ada Boost   \n",
       "\n",
       "   Hardware: Number of workers/kernels for parallel computing  \\\n",
       "0                                                  1            \n",
       "1                                                  1            \n",
       "2                                                  1            \n",
       "3                                                  1            \n",
       "4                                                  1            \n",
       "\n",
       "  Availability of a warm-start HP configuration  \\\n",
       "0                                            no   \n",
       "1                                            no   \n",
       "2                                           yes   \n",
       "3                                           yes   \n",
       "4                                           yes   \n",
       "\n",
       "   Number of maximum function evaluations/ trials budget  \\\n",
       "0                                              200.0       \n",
       "1                                                NaN       \n",
       "2                                              200.0       \n",
       "3                                                NaN       \n",
       "4                                                NaN       \n",
       "\n",
       "   Running time per trial [s]  Total Computing Time [s]  \\\n",
       "0                    2.078070                415.614018   \n",
       "1                         NaN                 40.000000   \n",
       "2                    2.090257                418.051303   \n",
       "3                         NaN                 10.000000   \n",
       "4                         NaN                 80.000000   \n",
       "\n",
       "   Dimensionality of HPs                     HP datatypes  \\\n",
       "0                      4  [continuous, discrete, nominal]   \n",
       "1                      4  [continuous, discrete, nominal]   \n",
       "2                      4  [continuous, discrete, nominal]   \n",
       "3                      4  [continuous, discrete, nominal]   \n",
       "4                      4  [continuous, discrete, nominal]   \n",
       "\n",
       "  Conditional HP space                         Detailed ML task  ...  \\\n",
       "0                   no  Prediction of Remaining Useful Lifetime  ...   \n",
       "1                   no  Prediction of Remaining Useful Lifetime  ...   \n",
       "2                   no  Prediction of Remaining Useful Lifetime  ...   \n",
       "3                   no  Prediction of Remaining Useful Lifetime  ...   \n",
       "4                   no  Prediction of Remaining Useful Lifetime  ...   \n",
       "\n",
       "  UR: quality demands User's programming ability  \\\n",
       "0                high                              \n",
       "1                high                              \n",
       "2                high                              \n",
       "3                high                              \n",
       "4                high                              \n",
       "\n",
       "   UR: Computer operating system  Obtainability of good approximate  \\\n",
       "0                          Linux            {'yes': 0.5, 'no': 0.5}   \n",
       "1                          Linux            {'yes': 0.5, 'no': 0.5}   \n",
       "2                          Linux            {'yes': 0.5, 'no': 0.5}   \n",
       "3                          Linux            {'yes': 0.5, 'no': 0.5}   \n",
       "4                          Linux            {'yes': 0.5, 'no': 0.5}   \n",
       "\n",
       "  Supports parallel evaluations Obtainability of gradients  \\\n",
       "0       {'yes': 0.5, 'no': 0.5}    {'yes': 0.5, 'no': 0.5}   \n",
       "1       {'yes': 0.5, 'no': 0.5}    {'yes': 0.5, 'no': 0.5}   \n",
       "2       {'yes': 0.5, 'no': 0.5}    {'yes': 0.5, 'no': 0.5}   \n",
       "3       {'yes': 0.5, 'no': 0.5}    {'yes': 0.5, 'no': 0.5}   \n",
       "4       {'yes': 0.5, 'no': 0.5}    {'yes': 0.5, 'no': 0.5}   \n",
       "\n",
       "          Noise in dataset Training Technique UR: need for model transparency  \\\n",
       "0  {'yes': 0.5, 'no': 0.5}            Offline                                   \n",
       "1  {'yes': 0.5, 'no': 0.5}            Offline                                   \n",
       "2  {'yes': 0.5, 'no': 0.5}            Offline                                   \n",
       "3  {'yes': 0.5, 'no': 0.5}            Offline                                   \n",
       "4  {'yes': 0.5, 'no': 0.5}            Offline                                   \n",
       "\n",
       "  UR: Availability of a well documented library  \n",
       "0                                                \n",
       "1                                                \n",
       "2                                                \n",
       "3                                                \n",
       "4                                                \n",
       "\n",
       "[5 rows x 25 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Machine Learning Algorithm</th>\n      <th>Hardware: Number of workers/kernels for parallel computing</th>\n      <th>Availability of a warm-start HP configuration</th>\n      <th>Number of maximum function evaluations/ trials budget</th>\n      <th>Running time per trial [s]</th>\n      <th>Total Computing Time [s]</th>\n      <th>Dimensionality of HPs</th>\n      <th>HP datatypes</th>\n      <th>Conditional HP space</th>\n      <th>Detailed ML task</th>\n      <th>...</th>\n      <th>UR: quality demands</th>\n      <th>User's programming ability</th>\n      <th>UR: Computer operating system</th>\n      <th>Obtainability of good approximate</th>\n      <th>Supports parallel evaluations</th>\n      <th>Obtainability of gradients</th>\n      <th>Noise in dataset</th>\n      <th>Training Technique</th>\n      <th>UR: need for model transparency</th>\n      <th>UR: Availability of a well documented library</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Ada Boost</td>\n      <td>1</td>\n      <td>no</td>\n      <td>200.0</td>\n      <td>2.078070</td>\n      <td>415.614018</td>\n      <td>4</td>\n      <td>[continuous, discrete, nominal]</td>\n      <td>no</td>\n      <td>Prediction of Remaining Useful Lifetime</td>\n      <td>...</td>\n      <td>high</td>\n      <td></td>\n      <td>Linux</td>\n      <td>{'yes': 0.5, 'no': 0.5}</td>\n      <td>{'yes': 0.5, 'no': 0.5}</td>\n      <td>{'yes': 0.5, 'no': 0.5}</td>\n      <td>{'yes': 0.5, 'no': 0.5}</td>\n      <td>Offline</td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Ada Boost</td>\n      <td>1</td>\n      <td>no</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>40.000000</td>\n      <td>4</td>\n      <td>[continuous, discrete, nominal]</td>\n      <td>no</td>\n      <td>Prediction of Remaining Useful Lifetime</td>\n      <td>...</td>\n      <td>high</td>\n      <td></td>\n      <td>Linux</td>\n      <td>{'yes': 0.5, 'no': 0.5}</td>\n      <td>{'yes': 0.5, 'no': 0.5}</td>\n      <td>{'yes': 0.5, 'no': 0.5}</td>\n      <td>{'yes': 0.5, 'no': 0.5}</td>\n      <td>Offline</td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Ada Boost</td>\n      <td>1</td>\n      <td>yes</td>\n      <td>200.0</td>\n      <td>2.090257</td>\n      <td>418.051303</td>\n      <td>4</td>\n      <td>[continuous, discrete, nominal]</td>\n      <td>no</td>\n      <td>Prediction of Remaining Useful Lifetime</td>\n      <td>...</td>\n      <td>high</td>\n      <td></td>\n      <td>Linux</td>\n      <td>{'yes': 0.5, 'no': 0.5}</td>\n      <td>{'yes': 0.5, 'no': 0.5}</td>\n      <td>{'yes': 0.5, 'no': 0.5}</td>\n      <td>{'yes': 0.5, 'no': 0.5}</td>\n      <td>Offline</td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Ada Boost</td>\n      <td>1</td>\n      <td>yes</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>10.000000</td>\n      <td>4</td>\n      <td>[continuous, discrete, nominal]</td>\n      <td>no</td>\n      <td>Prediction of Remaining Useful Lifetime</td>\n      <td>...</td>\n      <td>high</td>\n      <td></td>\n      <td>Linux</td>\n      <td>{'yes': 0.5, 'no': 0.5}</td>\n      <td>{'yes': 0.5, 'no': 0.5}</td>\n      <td>{'yes': 0.5, 'no': 0.5}</td>\n      <td>{'yes': 0.5, 'no': 0.5}</td>\n      <td>Offline</td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Ada Boost</td>\n      <td>1</td>\n      <td>yes</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>80.000000</td>\n      <td>4</td>\n      <td>[continuous, discrete, nominal]</td>\n      <td>no</td>\n      <td>Prediction of Remaining Useful Lifetime</td>\n      <td>...</td>\n      <td>high</td>\n      <td></td>\n      <td>Linux</td>\n      <td>{'yes': 0.5, 'no': 0.5}</td>\n      <td>{'yes': 0.5, 'no': 0.5}</td>\n      <td>{'yes': 0.5, 'no': 0.5}</td>\n      <td>{'yes': 0.5, 'no': 0.5}</td>\n      <td>Offline</td>\n      <td></td>\n      <td></td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 25 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 141
    }
   ],
   "source": [
    "df_use_case.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the BRBES for the BM use cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the brb model for the use cases from the BM study on compute the beliefs and rankings of the HPO techniques\n",
    "\n",
    "df_belief = pd.DataFrame([])\n",
    "df_rank = pd.DataFrame([])\n",
    "\n",
    "for idx, row in df_use_case.iterrows():\n",
    "    \n",
    "    use_case_dict = row.to_dict()\n",
    "    use_case_dict = {'A_' + k: v for k, v in use_case_dict.items()}\n",
    "\n",
    "    X = AttributeInput(use_case_dict)\n",
    "\n",
    "    # run brb model\n",
    "    belief_degrees = model.run(X)\n",
    "    belief_degrees = {k[2:]: v for k, v in zip(model.D, belief_degrees)}\n",
    "\n",
    "    # append results\n",
    "    df_belief = df_belief.append(belief_degrees, ignore_index=True)\n",
    "    \n",
    "    hpo_beliefs = {v: k for k, v in belief_degrees.items()}\n",
    "    hpo_beliefs = sorted(hpo_beliefs.items(), reverse=True)\n",
    "\n",
    "    # BEWARE: THE RANK IS 0-BASED\n",
    "    hpo_ranks = {hpo_belief[-1]: i for i, hpo_belief in enumerate(hpo_beliefs)}\n",
    "    \n",
    "    df_rank = df_rank.append(hpo_ranks, ignore_index=True)\n",
    "\n",
    "df_use_case.to_csv('use_cases.csv')\n",
    "df_belief.to_csv('hpo_beliefs.csv')\n",
    "df_rank.to_csv('hpo_ranks.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       ASHA  BOHAMIANN      BOHB    CMA-ES      DNGO  Default Values  \\\n",
       "0  0.051417   0.018876  0.138582  0.042050  0.008856        0.064043   \n",
       "1  0.055060   0.018346  0.136457  0.035970  0.007344        0.104301   \n",
       "2  0.050827   0.020221  0.138673  0.043166  0.008757        0.063304   \n",
       "3  0.054804   0.019988  0.141474  0.037561  0.007311        0.103806   \n",
       "4  0.055383   0.020195  0.139249  0.037953  0.007386        0.087795   \n",
       "\n",
       "    FABOLAS      GPBO  Grid Search        HB  HB-LCNet      HOAG      MTBO  \\\n",
       "0  0.019548  0.072556     0.015336  0.142985  0.028152  0.007255  0.005377   \n",
       "1  0.032509  0.063428     0.015297  0.158395  0.031254  0.006406  0.001878   \n",
       "2  0.019327  0.073360     0.015163  0.143025  0.027833  0.007174  0.005316   \n",
       "3  0.030680  0.062865     0.015227  0.157700  0.031110  0.006377  0.001870   \n",
       "4  0.022565  0.067707     0.015385  0.161372  0.031435  0.006443  0.001889   \n",
       "\n",
       "        PBT  Random Search       SHA      SMAC       TPE  \n",
       "0  0.056019       0.053760  0.072904  0.117930  0.071690  \n",
       "1  0.051676       0.042812  0.078816  0.097167  0.048965  \n",
       "2  0.055375       0.053142  0.072057  0.118252  0.072503  \n",
       "3  0.051436       0.040586  0.078445  0.096430  0.048473  \n",
       "4  0.051978       0.045097  0.079285  0.101786  0.053100  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ASHA</th>\n      <th>BOHAMIANN</th>\n      <th>BOHB</th>\n      <th>CMA-ES</th>\n      <th>DNGO</th>\n      <th>Default Values</th>\n      <th>FABOLAS</th>\n      <th>GPBO</th>\n      <th>Grid Search</th>\n      <th>HB</th>\n      <th>HB-LCNet</th>\n      <th>HOAG</th>\n      <th>MTBO</th>\n      <th>PBT</th>\n      <th>Random Search</th>\n      <th>SHA</th>\n      <th>SMAC</th>\n      <th>TPE</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.051417</td>\n      <td>0.018876</td>\n      <td>0.138582</td>\n      <td>0.042050</td>\n      <td>0.008856</td>\n      <td>0.064043</td>\n      <td>0.019548</td>\n      <td>0.072556</td>\n      <td>0.015336</td>\n      <td>0.142985</td>\n      <td>0.028152</td>\n      <td>0.007255</td>\n      <td>0.005377</td>\n      <td>0.056019</td>\n      <td>0.053760</td>\n      <td>0.072904</td>\n      <td>0.117930</td>\n      <td>0.071690</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.055060</td>\n      <td>0.018346</td>\n      <td>0.136457</td>\n      <td>0.035970</td>\n      <td>0.007344</td>\n      <td>0.104301</td>\n      <td>0.032509</td>\n      <td>0.063428</td>\n      <td>0.015297</td>\n      <td>0.158395</td>\n      <td>0.031254</td>\n      <td>0.006406</td>\n      <td>0.001878</td>\n      <td>0.051676</td>\n      <td>0.042812</td>\n      <td>0.078816</td>\n      <td>0.097167</td>\n      <td>0.048965</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.050827</td>\n      <td>0.020221</td>\n      <td>0.138673</td>\n      <td>0.043166</td>\n      <td>0.008757</td>\n      <td>0.063304</td>\n      <td>0.019327</td>\n      <td>0.073360</td>\n      <td>0.015163</td>\n      <td>0.143025</td>\n      <td>0.027833</td>\n      <td>0.007174</td>\n      <td>0.005316</td>\n      <td>0.055375</td>\n      <td>0.053142</td>\n      <td>0.072057</td>\n      <td>0.118252</td>\n      <td>0.072503</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.054804</td>\n      <td>0.019988</td>\n      <td>0.141474</td>\n      <td>0.037561</td>\n      <td>0.007311</td>\n      <td>0.103806</td>\n      <td>0.030680</td>\n      <td>0.062865</td>\n      <td>0.015227</td>\n      <td>0.157700</td>\n      <td>0.031110</td>\n      <td>0.006377</td>\n      <td>0.001870</td>\n      <td>0.051436</td>\n      <td>0.040586</td>\n      <td>0.078445</td>\n      <td>0.096430</td>\n      <td>0.048473</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.055383</td>\n      <td>0.020195</td>\n      <td>0.139249</td>\n      <td>0.037953</td>\n      <td>0.007386</td>\n      <td>0.087795</td>\n      <td>0.022565</td>\n      <td>0.067707</td>\n      <td>0.015385</td>\n      <td>0.161372</td>\n      <td>0.031435</td>\n      <td>0.006443</td>\n      <td>0.001889</td>\n      <td>0.051978</td>\n      <td>0.045097</td>\n      <td>0.079285</td>\n      <td>0.101786</td>\n      <td>0.053100</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 143
    }
   ],
   "source": [
    "df_belief.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0       HB\n",
       "1       HB\n",
       "2       HB\n",
       "3       HB\n",
       "4       HB\n",
       "5       HB\n",
       "6       HB\n",
       "7       HB\n",
       "8       HB\n",
       "9       HB\n",
       "10      HB\n",
       "11      HB\n",
       "12      HB\n",
       "13      HB\n",
       "14      HB\n",
       "15      HB\n",
       "16      HB\n",
       "17      HB\n",
       "18      HB\n",
       "19      HB\n",
       "20      HB\n",
       "21      HB\n",
       "22      HB\n",
       "23      HB\n",
       "24      HB\n",
       "25      HB\n",
       "26      HB\n",
       "27      HB\n",
       "28      HB\n",
       "29      HB\n",
       "30      HB\n",
       "31      HB\n",
       "32      HB\n",
       "33      HB\n",
       "34      HB\n",
       "35      HB\n",
       "36      HB\n",
       "37    BOHB\n",
       "38      HB\n",
       "39    BOHB\n",
       "40      HB\n",
       "41      HB\n",
       "42      HB\n",
       "43    GPBO\n",
       "44    GPBO\n",
       "45    GPBO\n",
       "46    GPBO\n",
       "47    GPBO\n",
       "48    GPBO\n",
       "49    GPBO\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 144
    }
   ],
   "source": [
    "df_belief.idxmax(axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Translation to max results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "BRBES avg. score (stdev): \t\t0.155 (0.23)\nRandomSearch avg. score (stdev): \t0.171 (0.24)\nDefault Values avg. score (stdev): \t0.739 (0.39)\n"
     ]
    }
   ],
   "source": [
    "use_test_loss = False\n",
    "\n",
    "brb_scores = list()  # Stores the scaled score achieved by the BRBES in each use case\n",
    "rs_scores = list()  # Stores the scaled score achieved by RS in each use case\n",
    "dv_scores = list()  # Stores the scaled score achieved by the Default HPs in each use case\n",
    "\n",
    "summary_df = df_use_case.copy(deep=True)\n",
    "\n",
    "for idx, use_case in df_use_case.iterrows():\n",
    "\n",
    "    # Identify the experiments (from the benchmarking study), that correspond to this specific use case\n",
    "    exp = maxr.loc[(maxr['ML-algorithm'] == ml_brb2bm_map[use_case['Machine Learning Algorithm']]) &\n",
    "        (maxr['Workers'] == use_case['Hardware: Number of workers/kernels for parallel computing']) &\n",
    "        (maxr['Warmstart'] == wst_brb2bm_map[use_case['Availability of a warm-start HP configuration']]) &\n",
    "        (maxr['Wall clock time [s]'] == use_case['Total Computing Time [s]']), :] \n",
    "        # TODO: Specify additional antecedent values here  -> e.g. quality demands, UR antecedents, robustness, etc.(Be careful: e.g. a 'high' robustness value should also be selected, if  only a 'low' robustness is required)\n",
    "\n",
    "    if len(exp) == 0:\n",
    "        continue\n",
    "    \n",
    "    if use_test_loss:  # If available, use the test loss for the ranking of HPO techniques\n",
    "    \n",
    "        # Check whether the test loss is available for this experiment\n",
    "        if exp['Mean (final test loss)'].isnull().any():\n",
    "            \n",
    "            # If not -> rank the HPO techniques based on the validation loss\n",
    "            hpos = exp.set_index('HPO-method')['Mean (final validation loss)'] \n",
    "            hpos.loc['Default Values'] = np.nanmean(exp['Validation baseline'])\n",
    "\n",
    "        else: \n",
    "            \n",
    "            # If available -> rank the HPO techniques based on the test loss\n",
    "            hpos = exp.set_index('HPO-method')['Mean (final test loss)'] \n",
    "            hpos.loc['Default Values'] = np.nanmean(exp['Test baseline'])\n",
    "    \n",
    "    else:  # Always use the validation loss\n",
    "\n",
    "        hpos = exp.set_index('HPO-method')['Mean (final validation loss)'] \n",
    "        hpos.loc['Default Values'] = np.nanmean(exp['Validation baseline'])\n",
    "\n",
    "    # Compute the scaled loss deviation for each HPO technique in this experiment\n",
    "    loss_arr = hpos.to_numpy()\n",
    "    min_value = np.nanmin(loss_arr)\n",
    "    max_value = np.nanmax(loss_arr[loss_arr != np.inf])\n",
    "    scaled_hpos = (hpos - min_value) / (max_value - min_value)\n",
    "\n",
    "    rec_hpo = df_belief.iloc[idx].idxmax(axis='columns')\n",
    "\n",
    "    brb_scores.append(scaled_hpos.loc[hpo_brb2bm_map[rec_hpo]])\n",
    "    rs_scores.append(scaled_hpos.loc['RandomSearch'])\n",
    "    dv_scores.append(scaled_hpos.loc['Default Values'])\n",
    "\n",
    "    summary_df.loc[idx, 'BRBES Recommendation'] = hpo_brb2bm_map[rec_hpo]\n",
    "    summary_df.loc[idx, 'Best HPO Technique'] = scaled_hpos.idxmin(axis=0)\n",
    "    summary_df.loc[idx, 'Distance Value'] = scaled_hpos.loc[hpo_brb2bm_map[rec_hpo]]\n",
    "\n",
    "print('BRBES avg. score (stdev): \\t\\t{:.3f} ({:.2f})'.format(np.mean(brb_scores), np.std(brb_scores)))\n",
    "print('RandomSearch avg. score (stdev): \\t{:.3f} ({:.2f})'.format(np.mean(rs_scores), np.std(rs_scores)))\n",
    "print('Default Values avg. score (stdev): \\t{:.3f} ({:.2f})'.format(np.mean(dv_scores), np.std(dv_scores)))\n",
    "\n",
    "if use_test_loss:\n",
    "    summary_fname = dataset + '_brbes_results_val_and_test_loss.csv'\n",
    "else:\n",
    "    summary_fname = dataset + '_brbes_results_val_loss_only.csv'\n",
    "\n",
    "summary_df.to_csv(os.path.join('./max_results', summary_fname))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}