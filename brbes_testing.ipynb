{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "from glob import glob\n",
    "from itertools import product\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from interval import interval, inf\n",
    "\n",
    "from brb.attr_input import AttributeInput\n",
    "from brb.brb import csv2BRB"
   ]
  },
  {
   "source": [
    "# Read the Rule Base and create the Expert System"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename =  'csv_HPO_BeliefRuleBase_wKO_v16.csv_RefVals_AntImp-1Mglobscaled.csv'\n",
    "filepath = os.path.join('csv_rulebases', filename)\n",
    "\n",
    "assert os.path.exists(filepath), \"rulebase doesn't exist\"\n",
    "\n",
    "# create model from rules.csv\n",
    "model = csv2BRB(filepath,\n",
    "                #'csv_rulebases/csv_ML_BeliefRuleBase_v5.csv_spec_refvals*ant_imp--scaled.csv',\n",
    "                #'csv_rulebases/csv_HPO_BeliefRuleBase_v11.csv_spec_refvals*ant_imp--scaled.csv',\n",
    "                antecedents_prefix='A_',\n",
    "                consequents_prefix='D_',\n",
    "                deltas_prefix='del_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.U_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.U[10].referential_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Max's results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['Trial-ID', 'HPO-library', 'HPO-method', 'ML-algorithm', 'Runs',\n",
       "       'Evaluations', 'Workers', 'GPU', 'Warmstart', 'Wall clock time [s]',\n",
       "       't outperform default [s]', 'Mean (final validation loss)',\n",
       "       'Validation baseline', 'Area under curve (AUC)',\n",
       "       'Mean (final test loss)', 'Test loss ratio (default / best)',\n",
       "       'Test baseline', 'Interquartile range (final test loss)',\n",
       "       't best configuration [s]', 'Generalization error',\n",
       "       'Evaluations for best configuration', 'Crashes', '# training instances',\n",
       "       '# training features', '# test instances', '# test features', 'dataset',\n",
       "       '# cont. HPs', '# int. HPs', '# cat. HPs', 'loss_metric', 'Robustness',\n",
       "       'UR: Availability of a well documented library',\n",
       "       'UR: Need for model transparency', 'User's programming ability'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "dataset = 'turbofan'  # 'turbofan', 'scania', 'sensor\n",
    "ml_task = 'Regression'  # 'Regression', 'Binary Classification', 'Multiclass Classification'\n",
    "\n",
    "file_name = 'expanded_metrics_' + dataset + '.csv'\n",
    "maxr_fpath = os.path.join('max_results', file_name)\n",
    "\n",
    "maxr = pd.read_csv(maxr_fpath, index_col=0)\n",
    "\n",
    "maxr.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxr.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input generation for the Expert System (Use Cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping between BRB and BM notation\n",
    "\n",
    "# Map ML algorithms: BRB -> BM\n",
    "# TODO: Needs to be expanded to include classification algorithms\n",
    "\n",
    "if ml_task == 'Regression':\n",
    "    \n",
    "    ml_brb2bm_map = {\n",
    "        'Ada Boost': 'AdaBoostRegressor',\n",
    "        'Decision Tree': 'DecisionTreeRegressor',\n",
    "        'Support Vector Machine': 'SVR',\n",
    "        'KNN': 'KNNRegressor',\n",
    "        'Gradient Boosting Machine': 'LGBMRegressor',\n",
    "        'Random Forest': 'RandomForestRegressor',\n",
    "        'XGBoost': 'XGBoostRegressor',\n",
    "        'ElasticNet': 'ElasticNet',\n",
    "        'Multilayer Perceptron': 'KerasRegressor'\n",
    "    }\n",
    "\n",
    "elif ml_task == 'Binary Classification' or ml_task == 'Multiclass Classification':\n",
    "\n",
    "    ml_brb2bm_map = {\n",
    "        'Ada Boost': 'AdaBoostClassifier',\n",
    "        'Decision Tree': 'DecisionTreeClassifier',\n",
    "        'Support Vector Machine': 'SVC',\n",
    "        'KNN': 'KNNClassifier',\n",
    "        'Gradient Boosting Machine': 'LGBMClassifier',\n",
    "        'Random Forest': 'RandomForestClassifier',\n",
    "        'XGBoost': 'XGBoostClassifier',\n",
    "        'Logistic Regression': 'LogisticRegression',\n",
    "        'Multilayer Perceptron': 'KerasClassifier',\n",
    "        'NaiveBayes': 'NaiveBayes'\n",
    "    }\n",
    "\n",
    "else:\n",
    "    raise Exception('Unknown ML task!')\n",
    "\n",
    "# Map ML algorithms: BM -> BRB\n",
    "ml_bm2brb_map = {v: k for k, v in ml_brb2bm_map.items()}\n",
    "\n",
    "# Map HPO techniques: BRB -> BM\n",
    "hpo_brb2bm_map = {\n",
    "    'BOHAMIANN': 'Bohamiann',\n",
    "    'BOHB': 'BOHB',\n",
    "    'CMA-ES': 'CMA-ES',\n",
    "    'FABOLAS': 'Fabolas',\n",
    "    'GPBO': 'GPBO',\n",
    "    'HB': 'Hyperband',\n",
    "    'Random Search': 'RandomSearch',\n",
    "    'SMAC': 'SMAC',\n",
    "    'TPE': 'TPE',\n",
    "    'Default Values': 'Default Values'\n",
    "}\n",
    "\n",
    "# Map HPO techniques: BM -> BRB\n",
    "hpo_bm2brb_map = {v: k for k, v in hpo_brb2bm_map.items()}\n",
    "\n",
    "# Map warm tart notation: BRB -> BM\n",
    "wst_brb2bm_map = {'yes': True, 'no': False}\n",
    "\n",
    "wst_bm2brb_map = {v: k for k, v in wst_brb2bm_map.items()}\n",
    "\n",
    "# Map ML algorithms with HP data types\n",
    "bmalgo2paratype_map = {\n",
    "    'RandomForestRegressor': '[continuous, discrete, nominal]',\n",
    "    'RandomForestClassifier': '[continuous, discrete, nominal]',\n",
    "    'MLPRegressor': '[discrete, nominal]',\n",
    "    'MLPClassifier': '[discrete, nominal]',\n",
    "    'SVR': '[continuous, nominal]',\n",
    "    'SVC': '[continuous, nominal]',\n",
    "    'KerasRegressor': '[continuous, discrete, nominal]',\n",
    "    'KerasClassifier': '[continuous, discrete, nominal]',\n",
    "    'XGBoostClassifier': '[continuous, discrete, nominal]',\n",
    "    'XGBoostRegressor': '[continuous, discrete, nominal]',\n",
    "    'AdaBoostRegressor': '[continuous, discrete, nominal]',\n",
    "    'AdaBoostClassifier': '[continuous, discrete, nominal]',\n",
    "    'DecisionTreeRegressor': '[continuous, discrete]',\n",
    "    'DecisionTreeClassifier': '[continuous, discrete]',\n",
    "    'LinearRegression': '[nominal]',\n",
    "    'KNNRegressor': '[discrete, nominal]',\n",
    "    'KNNClassifier': '[discrete, nominal]',\n",
    "    'LGBMRegressor': '[continuous, discrete]',\n",
    "    'LGBMClassifier': '[continuous, discrete]',\n",
    "    'LogisticRegression': '[continuous, discrete, nominal]',\n",
    "    'ElasticNet': '[continuous, discrete, nominal]',\n",
    "    'NaiveBayes': '[continuous]'}\n",
    "\n",
    "# Map ML algorithms with conditional / non-conditional HPs\n",
    "bmalgo2cond_map = {\n",
    "    'RandomForestRegressor': 'no',\n",
    "    'RandomForestClassifier': 'no',\n",
    "    'MLPRegressor': 'no',\n",
    "    'MLPClassifier': 'no',\n",
    "    'SVR': 'no',\n",
    "    'SVC': 'no',\n",
    "    'KerasRegressor': 'no',\n",
    "    'KerasClassifier': 'no',\n",
    "    'XGBoostClassifier': 'yes',\n",
    "    'XGBoostRegressor': 'yes',\n",
    "    'AdaBoostRegressor': 'no',\n",
    "    'AdaBoostClassifier': 'no',\n",
    "    'DecisionTreeRegressor': 'no',\n",
    "    'DecisionTreeClassifier': 'no',\n",
    "    'LinearRegression': 'no',\n",
    "    'KNNRegressor': 'no',\n",
    "    'KNNClassifier': 'no',\n",
    "    'LGBMRegressor': 'no',\n",
    "    'LGBMClassifier': 'no',\n",
    "    'LogisticRegression': 'no',\n",
    "    'ElasticNet': 'no',\n",
    "    'NaiveBayes': 'no'}\n",
    "\n",
    "# Map dataset information with some (constant) antecedents\n",
    "datset2constant_map = {\n",
    "    'turbofan': {\n",
    "        \"Detailed ML task\": 'Prediction of Remaining Useful Lifetime',\n",
    "        \"Production application area\": 'Predictive Maintenance',\n",
    "        \"Input Data\": 'Tabular Data',\n",
    "        \"Ratio training to test dataset\": 4,\n",
    "        \"ML task\": 'Regression'\n",
    "        },\n",
    "    'scania': {\n",
    "        \"Detailed ML task\": 'Prediction of Part Failure',\n",
    "        \"Production application area\": 'Predictive Maintenance',\n",
    "        \"Input Data\": 'Tabular Data',\n",
    "        \"Ratio training to test dataset\": 4,\n",
    "        \"ML task\": 'Binary Classification'\n",
    "    },\n",
    "    'sensor': {\n",
    "        \"Detailed ML task\": 'Prediction of Product Quality',\n",
    "        \"Production application area\": 'Predictive Quality',\n",
    "        \"Input Data\": 'Tabular Data',\n",
    "        \"Ratio training to test dataset\": 4,\n",
    "        \"ML task\": 'Multiclass Classification'\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame to store the use cases for the evaluation of the BRBES (each row corresponds to a single use case)\n",
    "df_use_case = pd.DataFrame([])\n",
    "df_use_case['Machine Learning Algorithm'] = maxr['ML-algorithm'].map(ml_bm2brb_map)\n",
    "df_use_case['Hardware: Number of workers/kernels for parallel computing'] = maxr['Workers']\n",
    "df_use_case['Availability of a warm-start HP configuration'] = maxr['Warmstart'].map(wst_bm2brb_map)\n",
    "df_use_case['Number of maximum function evaluations/ trials budget'] = maxr['Evaluations']\n",
    "# df_use_case['Running time per trial [s]'] = [interval[0, 30]] * len(maxr['ML-algorithm']) # TODO: Calculation necessary\n",
    "df_use_case['Running time per trial [s]'] = maxr['Wall clock time [s]'] / maxr['Evaluations']\n",
    "df_use_case['Total Computing Time [s]'] = maxr['Wall clock time [s]']\n",
    "df_use_case['Dimensionality of HPs'] = maxr['# cont. HPs'] + maxr['# int. HPs'] + maxr['# cat. HPs']\n",
    "df_use_case['HP datatypes'] = maxr['ML-algorithm'].map(bmalgo2paratype_map)\n",
    "df_use_case['Conditional HP space'] = maxr['ML-algorithm'].map(bmalgo2cond_map)\n",
    "df_use_case[\"Detailed ML task\"] = datset2constant_map[dataset][\"Detailed ML task\"]\n",
    "df_use_case[\"Production application area\"] = datset2constant_map[dataset][\"Production application area\"]\n",
    "df_use_case['Input Data'] = datset2constant_map[dataset][\"Input Data\"]\n",
    "df_use_case['#Instances training dataset'] = maxr['# training instances']\n",
    "df_use_case['Ratio training to test dataset'] = datset2constant_map[dataset][\"Ratio training to test dataset\"]\n",
    "df_use_case['ML task'] = datset2constant_map[dataset][\"ML task\"]\n",
    "df_use_case[\"UR: need for model transparency\"] = maxr[\"UR: Need for model transparency\"]\n",
    "df_use_case[\"UR: Availability of a well documented library\"] = maxr[\"UR: Availability of a well documented library\"]\n",
    "df_use_case[\"User's programming ability\"] = maxr[\"User's programming ability\"]\n",
    "\n",
    "# fixed antecedents (cannot yet be derived from the metrics .csv file)\n",
    "df_use_case[\"UR: quality demands\"] = 'high'  # TODO: Keep this antecedent fixed?\n",
    "df_use_case[\"UR: Computer operating system\"] = 'Linux'\n",
    "df_use_case[\"Obtainability of good approximate\"] = [{'yes':0.5, 'no':0.5}] * len(maxr['ML-algorithm'])\n",
    "df_use_case[\"Supports parallel evaluations\"] = [{'yes':0.5, 'no':0.5}] * len(maxr['ML-algorithm'])\n",
    "df_use_case[\"Obtainability of gradients\"] = [{'yes':0.5, 'no':0.5}] * len(maxr['ML-algorithm'])\n",
    "df_use_case[\"Noise in dataset\"] = [{'yes':0.5, 'no':0.5}] * len(maxr['ML-algorithm'])\n",
    "df_use_case[\"Training Technique\"] = \"Offline\"\n",
    "\n",
    "# 'Robustness' antecedent is not available for the current version of the rule base\n",
    "# df_use_case['Robustness'] = maxr['Robustness']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns with dict entries cause problems when identifying duplicates (not hashable)\n",
    "dict_cols = {'Obtainability of good approximate', 'Supports parallel evaluations', 'Obtainability of gradients', 'Noise in dataset'}\n",
    "non_dict_cols = set(df_use_case.columns) - dict_cols\n",
    "\n",
    "# Remove duplicate use cases (Each use case is contained x times, where x is the number of HPO techniques applied on this use case)\n",
    "df_use_case.drop_duplicates(subset=non_dict_cols, inplace=True, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  Machine Learning Algorithm  \\\n",
       "0                  Ada Boost   \n",
       "1                  Ada Boost   \n",
       "2                  Ada Boost   \n",
       "3                  Ada Boost   \n",
       "4                  Ada Boost   \n",
       "\n",
       "   Hardware: Number of workers/kernels for parallel computing  \\\n",
       "0                                                  1            \n",
       "1                                                  1            \n",
       "2                                                  1            \n",
       "3                                                  1            \n",
       "4                                                  1            \n",
       "\n",
       "  Availability of a warm-start HP configuration  \\\n",
       "0                                            no   \n",
       "1                                            no   \n",
       "2                                            no   \n",
       "3                                            no   \n",
       "4                                            no   \n",
       "\n",
       "   Number of maximum function evaluations/ trials budget  \\\n",
       "0                                              200.0       \n",
       "1                                                NaN       \n",
       "2                                              200.0       \n",
       "3                                                NaN       \n",
       "4                                              200.0       \n",
       "\n",
       "   Running time per trial [s]  Total Computing Time [s]  \\\n",
       "0                     2.07807                415.614018   \n",
       "1                         NaN                 40.000000   \n",
       "2                     2.07807                415.614018   \n",
       "3                         NaN                 40.000000   \n",
       "4                     2.07807                415.614018   \n",
       "\n",
       "   Dimensionality of HPs                     HP datatypes  \\\n",
       "0                      4  [continuous, discrete, nominal]   \n",
       "1                      4  [continuous, discrete, nominal]   \n",
       "2                      4  [continuous, discrete, nominal]   \n",
       "3                      4  [continuous, discrete, nominal]   \n",
       "4                      4  [continuous, discrete, nominal]   \n",
       "\n",
       "  Conditional HP space                         Detailed ML task  ...  \\\n",
       "0                   no  Prediction of Remaining Useful Lifetime  ...   \n",
       "1                   no  Prediction of Remaining Useful Lifetime  ...   \n",
       "2                   no  Prediction of Remaining Useful Lifetime  ...   \n",
       "3                   no  Prediction of Remaining Useful Lifetime  ...   \n",
       "4                   no  Prediction of Remaining Useful Lifetime  ...   \n",
       "\n",
       "  UR: need for model transparency  \\\n",
       "0                              no   \n",
       "1                              no   \n",
       "2                              no   \n",
       "3                              no   \n",
       "4                              no   \n",
       "\n",
       "  UR: Availability of a well documented library  User's programming ability  \\\n",
       "0                                            no                      medium   \n",
       "1                                            no                      medium   \n",
       "2                                            no                        high   \n",
       "3                                            no                        high   \n",
       "4                                           yes                      medium   \n",
       "\n",
       "   UR: quality demands UR: Computer operating system  \\\n",
       "0                 high                         Linux   \n",
       "1                 high                         Linux   \n",
       "2                 high                         Linux   \n",
       "3                 high                         Linux   \n",
       "4                 high                         Linux   \n",
       "\n",
       "  Obtainability of good approximate Supports parallel evaluations  \\\n",
       "0           {'yes': 0.5, 'no': 0.5}       {'yes': 0.5, 'no': 0.5}   \n",
       "1           {'yes': 0.5, 'no': 0.5}       {'yes': 0.5, 'no': 0.5}   \n",
       "2           {'yes': 0.5, 'no': 0.5}       {'yes': 0.5, 'no': 0.5}   \n",
       "3           {'yes': 0.5, 'no': 0.5}       {'yes': 0.5, 'no': 0.5}   \n",
       "4           {'yes': 0.5, 'no': 0.5}       {'yes': 0.5, 'no': 0.5}   \n",
       "\n",
       "  Obtainability of gradients         Noise in dataset Training Technique  \n",
       "0    {'yes': 0.5, 'no': 0.5}  {'yes': 0.5, 'no': 0.5}            Offline  \n",
       "1    {'yes': 0.5, 'no': 0.5}  {'yes': 0.5, 'no': 0.5}            Offline  \n",
       "2    {'yes': 0.5, 'no': 0.5}  {'yes': 0.5, 'no': 0.5}            Offline  \n",
       "3    {'yes': 0.5, 'no': 0.5}  {'yes': 0.5, 'no': 0.5}            Offline  \n",
       "4    {'yes': 0.5, 'no': 0.5}  {'yes': 0.5, 'no': 0.5}            Offline  \n",
       "\n",
       "[5 rows x 25 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Machine Learning Algorithm</th>\n      <th>Hardware: Number of workers/kernels for parallel computing</th>\n      <th>Availability of a warm-start HP configuration</th>\n      <th>Number of maximum function evaluations/ trials budget</th>\n      <th>Running time per trial [s]</th>\n      <th>Total Computing Time [s]</th>\n      <th>Dimensionality of HPs</th>\n      <th>HP datatypes</th>\n      <th>Conditional HP space</th>\n      <th>Detailed ML task</th>\n      <th>...</th>\n      <th>UR: need for model transparency</th>\n      <th>UR: Availability of a well documented library</th>\n      <th>User's programming ability</th>\n      <th>UR: quality demands</th>\n      <th>UR: Computer operating system</th>\n      <th>Obtainability of good approximate</th>\n      <th>Supports parallel evaluations</th>\n      <th>Obtainability of gradients</th>\n      <th>Noise in dataset</th>\n      <th>Training Technique</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Ada Boost</td>\n      <td>1</td>\n      <td>no</td>\n      <td>200.0</td>\n      <td>2.07807</td>\n      <td>415.614018</td>\n      <td>4</td>\n      <td>[continuous, discrete, nominal]</td>\n      <td>no</td>\n      <td>Prediction of Remaining Useful Lifetime</td>\n      <td>...</td>\n      <td>no</td>\n      <td>no</td>\n      <td>medium</td>\n      <td>high</td>\n      <td>Linux</td>\n      <td>{'yes': 0.5, 'no': 0.5}</td>\n      <td>{'yes': 0.5, 'no': 0.5}</td>\n      <td>{'yes': 0.5, 'no': 0.5}</td>\n      <td>{'yes': 0.5, 'no': 0.5}</td>\n      <td>Offline</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Ada Boost</td>\n      <td>1</td>\n      <td>no</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>40.000000</td>\n      <td>4</td>\n      <td>[continuous, discrete, nominal]</td>\n      <td>no</td>\n      <td>Prediction of Remaining Useful Lifetime</td>\n      <td>...</td>\n      <td>no</td>\n      <td>no</td>\n      <td>medium</td>\n      <td>high</td>\n      <td>Linux</td>\n      <td>{'yes': 0.5, 'no': 0.5}</td>\n      <td>{'yes': 0.5, 'no': 0.5}</td>\n      <td>{'yes': 0.5, 'no': 0.5}</td>\n      <td>{'yes': 0.5, 'no': 0.5}</td>\n      <td>Offline</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Ada Boost</td>\n      <td>1</td>\n      <td>no</td>\n      <td>200.0</td>\n      <td>2.07807</td>\n      <td>415.614018</td>\n      <td>4</td>\n      <td>[continuous, discrete, nominal]</td>\n      <td>no</td>\n      <td>Prediction of Remaining Useful Lifetime</td>\n      <td>...</td>\n      <td>no</td>\n      <td>no</td>\n      <td>high</td>\n      <td>high</td>\n      <td>Linux</td>\n      <td>{'yes': 0.5, 'no': 0.5}</td>\n      <td>{'yes': 0.5, 'no': 0.5}</td>\n      <td>{'yes': 0.5, 'no': 0.5}</td>\n      <td>{'yes': 0.5, 'no': 0.5}</td>\n      <td>Offline</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Ada Boost</td>\n      <td>1</td>\n      <td>no</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>40.000000</td>\n      <td>4</td>\n      <td>[continuous, discrete, nominal]</td>\n      <td>no</td>\n      <td>Prediction of Remaining Useful Lifetime</td>\n      <td>...</td>\n      <td>no</td>\n      <td>no</td>\n      <td>high</td>\n      <td>high</td>\n      <td>Linux</td>\n      <td>{'yes': 0.5, 'no': 0.5}</td>\n      <td>{'yes': 0.5, 'no': 0.5}</td>\n      <td>{'yes': 0.5, 'no': 0.5}</td>\n      <td>{'yes': 0.5, 'no': 0.5}</td>\n      <td>Offline</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Ada Boost</td>\n      <td>1</td>\n      <td>no</td>\n      <td>200.0</td>\n      <td>2.07807</td>\n      <td>415.614018</td>\n      <td>4</td>\n      <td>[continuous, discrete, nominal]</td>\n      <td>no</td>\n      <td>Prediction of Remaining Useful Lifetime</td>\n      <td>...</td>\n      <td>no</td>\n      <td>yes</td>\n      <td>medium</td>\n      <td>high</td>\n      <td>Linux</td>\n      <td>{'yes': 0.5, 'no': 0.5}</td>\n      <td>{'yes': 0.5, 'no': 0.5}</td>\n      <td>{'yes': 0.5, 'no': 0.5}</td>\n      <td>{'yes': 0.5, 'no': 0.5}</td>\n      <td>Offline</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 25 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "df_use_case.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the BRBES for the BM use cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the brb model for the use cases from the BM study on compute the beliefs and rankings of the HPO techniques\n",
    "\n",
    "df_belief = pd.DataFrame([])\n",
    "df_rank = pd.DataFrame([])\n",
    "\n",
    "for idx, row in df_use_case.iterrows():\n",
    "    \n",
    "    use_case_dict = row.to_dict()\n",
    "    use_case_dict = {'A_' + k: v for k, v in use_case_dict.items()}\n",
    "\n",
    "    X = AttributeInput(use_case_dict)\n",
    "\n",
    "    # run brb model\n",
    "    belief_degrees = model.run(X)\n",
    "    belief_degrees = {k[2:]: v for k, v in zip(model.D, belief_degrees)}\n",
    "\n",
    "    # append results\n",
    "    df_belief = df_belief.append(belief_degrees, ignore_index=True)\n",
    "    \n",
    "    hpo_beliefs = {v: k for k, v in belief_degrees.items()}\n",
    "    hpo_beliefs = sorted(hpo_beliefs.items(), reverse=True)\n",
    "\n",
    "    # BEWARE: THE RANK IS 0-BASED\n",
    "    hpo_ranks = {hpo_belief[-1]: i for i, hpo_belief in enumerate(hpo_beliefs)}\n",
    "    \n",
    "    df_rank = df_rank.append(hpo_ranks, ignore_index=True)\n",
    "\n",
    "df_use_case.to_csv('use_cases.csv')\n",
    "df_belief.to_csv('hpo_beliefs.csv')\n",
    "df_rank.to_csv('hpo_ranks.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       ASHA  BOHAMIANN      BOHB    CMA-ES      DNGO  Default Values  \\\n",
       "0  0.049629   0.018307  0.135880  0.044356  0.008615        0.058729   \n",
       "1  0.053025   0.017763  0.133739  0.038233  0.007142        0.096893   \n",
       "2  0.049861   0.018390  0.137677  0.044646  0.008654        0.058476   \n",
       "3  0.053292   0.017850  0.135686  0.038516  0.007177        0.096788   \n",
       "4  0.046065   0.017017  0.134681  0.049092  0.008010        0.061992   \n",
       "\n",
       "    FABOLAS      GPBO  Grid Search        HB  HB-LCNet      HOAG      MTBO  \\\n",
       "0  0.018883  0.075486     0.014942  0.138979  0.027187  0.007015  0.005200   \n",
       "1  0.031323  0.067044     0.014882  0.153554  0.030114  0.006179  0.001814   \n",
       "2  0.020235  0.075206     0.015025  0.139375  0.028588  0.007971  0.005224   \n",
       "3  0.032887  0.066690     0.014971  0.154053  0.031669  0.007222  0.001822   \n",
       "4  0.017547  0.077629     0.021576  0.137550  0.025256  0.006524  0.004835   \n",
       "\n",
       "        PBT  Random Search       SHA      SMAC       TPE  \n",
       "0  0.057323       0.060831  0.070711  0.120655  0.075036  \n",
       "1  0.053319       0.050949  0.076279  0.100993  0.053334  \n",
       "2  0.057530       0.053816  0.070998  0.120895  0.075144  \n",
       "3  0.053521       0.043269  0.076616  0.101145  0.053338  \n",
       "4  0.053198       0.063653  0.065708  0.120420  0.077865  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ASHA</th>\n      <th>BOHAMIANN</th>\n      <th>BOHB</th>\n      <th>CMA-ES</th>\n      <th>DNGO</th>\n      <th>Default Values</th>\n      <th>FABOLAS</th>\n      <th>GPBO</th>\n      <th>Grid Search</th>\n      <th>HB</th>\n      <th>HB-LCNet</th>\n      <th>HOAG</th>\n      <th>MTBO</th>\n      <th>PBT</th>\n      <th>Random Search</th>\n      <th>SHA</th>\n      <th>SMAC</th>\n      <th>TPE</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.049629</td>\n      <td>0.018307</td>\n      <td>0.135880</td>\n      <td>0.044356</td>\n      <td>0.008615</td>\n      <td>0.058729</td>\n      <td>0.018883</td>\n      <td>0.075486</td>\n      <td>0.014942</td>\n      <td>0.138979</td>\n      <td>0.027187</td>\n      <td>0.007015</td>\n      <td>0.005200</td>\n      <td>0.057323</td>\n      <td>0.060831</td>\n      <td>0.070711</td>\n      <td>0.120655</td>\n      <td>0.075036</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.053025</td>\n      <td>0.017763</td>\n      <td>0.133739</td>\n      <td>0.038233</td>\n      <td>0.007142</td>\n      <td>0.096893</td>\n      <td>0.031323</td>\n      <td>0.067044</td>\n      <td>0.014882</td>\n      <td>0.153554</td>\n      <td>0.030114</td>\n      <td>0.006179</td>\n      <td>0.001814</td>\n      <td>0.053319</td>\n      <td>0.050949</td>\n      <td>0.076279</td>\n      <td>0.100993</td>\n      <td>0.053334</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.049861</td>\n      <td>0.018390</td>\n      <td>0.137677</td>\n      <td>0.044646</td>\n      <td>0.008654</td>\n      <td>0.058476</td>\n      <td>0.020235</td>\n      <td>0.075206</td>\n      <td>0.015025</td>\n      <td>0.139375</td>\n      <td>0.028588</td>\n      <td>0.007971</td>\n      <td>0.005224</td>\n      <td>0.057530</td>\n      <td>0.053816</td>\n      <td>0.070998</td>\n      <td>0.120895</td>\n      <td>0.075144</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.053292</td>\n      <td>0.017850</td>\n      <td>0.135686</td>\n      <td>0.038516</td>\n      <td>0.007177</td>\n      <td>0.096788</td>\n      <td>0.032887</td>\n      <td>0.066690</td>\n      <td>0.014971</td>\n      <td>0.154053</td>\n      <td>0.031669</td>\n      <td>0.007222</td>\n      <td>0.001822</td>\n      <td>0.053521</td>\n      <td>0.043269</td>\n      <td>0.076616</td>\n      <td>0.101145</td>\n      <td>0.053338</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.046065</td>\n      <td>0.017017</td>\n      <td>0.134681</td>\n      <td>0.049092</td>\n      <td>0.008010</td>\n      <td>0.061992</td>\n      <td>0.017547</td>\n      <td>0.077629</td>\n      <td>0.021576</td>\n      <td>0.137550</td>\n      <td>0.025256</td>\n      <td>0.006524</td>\n      <td>0.004835</td>\n      <td>0.053198</td>\n      <td>0.063653</td>\n      <td>0.065708</td>\n      <td>0.120420</td>\n      <td>0.077865</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 54
    }
   ],
   "source": [
    "df_belief.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0      HB\n",
       "1      HB\n",
       "2      HB\n",
       "3      HB\n",
       "4      HB\n",
       "       ..\n",
       "595    HB\n",
       "596    HB\n",
       "597    HB\n",
       "598    HB\n",
       "599    HB\n",
       "Length: 600, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "df_belief.idxmax(axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Translation to max results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['CMA-ES', 'GPBO', 'RandomSearch', 'SMAC', 'TPE', 'Default Values'], dtype='object', name='HPO-method')"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "scaled_hpos.keys()\n"
   ]
  },
  {
   "source": [
    "use_test_loss = False\n",
    "\n",
    "brb_scores = list()  # Stores the scaled score achieved by the BRBES in each use case\n",
    "rs_scores = list()  # Stores the scaled score achieved by RS in each use case\n",
    "dv_scores = list()  # Stores the scaled score achieved by the Default HPs in each use case\n",
    "\n",
    "summary_df = df_use_case.copy(deep=True)\n",
    "\n",
    "for idx, use_case in df_use_case.iterrows():\n",
    "\n",
    "    # Identify the experiments (from the benchmarking study), that correspond to this specific use case\n",
    "    exp = maxr.loc[(maxr['ML-algorithm'] == ml_brb2bm_map[use_case['Machine Learning Algorithm']]) &\n",
    "        (maxr['Workers'] == use_case['Hardware: Number of workers/kernels for parallel computing']) &\n",
    "        (maxr['Warmstart'] == wst_brb2bm_map[use_case['Availability of a warm-start HP configuration']]) &\n",
    "        (maxr['Wall clock time [s]'] == use_case['Total Computing Time [s]']) &\n",
    "        (maxr[\"User's programming ability\"] == use_case[\"User's programming ability\"]) &\n",
    "        (maxr['UR: Need for model transparency'] == use_case['UR: need for model transparency']) &\n",
    "        (maxr['UR: Availability of a well documented library'] == use_case['UR: Availability of a well documented library']) &\n",
    "        (maxr['Robustness'] == 'low'), :] \n",
    "        # TODO: Specify additional antecedent values here  -> i.e. Quality Demands, Robustness\n",
    "\n",
    "    if len(exp) == 0:\n",
    "        continue\n",
    "    \n",
    "    if use_test_loss:  # If available, use the test loss for the ranking of HPO techniques\n",
    "    \n",
    "        # Check whether the test loss is available for this experiment\n",
    "        if exp['Mean (final test loss)'].isnull().any():\n",
    "            \n",
    "            # If not -> rank the HPO techniques based on the validation loss\n",
    "            hpos = exp.set_index('HPO-method')['Mean (final validation loss)'] \n",
    "            hpos.loc['Default Values'] = np.nanmean(exp['Validation baseline'])\n",
    "\n",
    "        else: \n",
    "            \n",
    "            # If available -> rank the HPO techniques based on the test loss\n",
    "            hpos = exp.set_index('HPO-method')['Mean (final test loss)'] \n",
    "            hpos.loc['Default Values'] = np.nanmean(exp['Test baseline'])\n",
    "    \n",
    "    else:  # Always use the validation loss\n",
    "\n",
    "        hpos = exp.set_index('HPO-method')['Mean (final validation loss)'] \n",
    "        hpos.loc['Default Values'] = np.nanmean(exp['Validation baseline'])\n",
    "\n",
    "    # Compute the scaled loss deviation for each HPO technique in this experiment\n",
    "    loss_arr = hpos.to_numpy()\n",
    "    min_value = np.nanmin(loss_arr)\n",
    "    max_value = np.nanmax(loss_arr[loss_arr != np.inf])\n",
    "    scaled_hpos = (hpos - min_value) / (max_value - min_value)\n",
    "\n",
    "    rec_hpo = df_belief.iloc[idx].idxmax(axis='columns')\n",
    "\n",
    "    # TODO: Continue here\n",
    "    if hpo_brb2bm_map[rec_hpo] not in scaled_hpos.keys():\n",
    "        brb_scores.append(np.nan)\n",
    "    else:\n",
    "        brb_scores.append(scaled_hpos.loc[hpo_brb2bm_map[rec_hpo]])\n",
    "\n",
    "    rs_scores.append(scaled_hpos.loc['RandomSearch'])\n",
    "    dv_scores.append(scaled_hpos.loc['Default Values'])\n",
    "\n",
    "    summary_df.loc[idx, 'BRBES Recommendation'] = hpo_brb2bm_map[rec_hpo]\n",
    "    summary_df.loc[idx, 'Best HPO Technique'] = scaled_hpos.idxmin(axis=0)\n",
    "    summary_df.loc[idx, 'Distance Value'] = scaled_hpos.loc[hpo_brb2bm_map[rec_hpo]]\n",
    "\n",
    "print('BRBES avg. score (stdev): \\t\\t{:.3f} ({:.2f})'.format(np.nanmean(brb_scores), np.nanstd(brb_scores)))\n",
    "print('RandomSearch avg. score (stdev): \\t{:.3f} ({:.2f})'.format(np.nanmean(rs_scores), np.nanstd(rs_scores)))\n",
    "print('Default Values avg. score (stdev): \\t{:.3f} ({:.2f})'.format(np.nanmean(dv_scores), np.nanstd(dv_scores)))\n",
    "\n",
    "if use_test_loss:\n",
    "    summary_fname = dataset + '_brbes_results_val_and_test_loss.csv'\n",
    "else:\n",
    "    summary_fname = dataset + '_brbes_results_val_loss_only.csv'\n",
    "\n",
    "summary_df.to_csv(os.path.join('./max_results', summary_fname))"
   ],
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "execution_count": 19,
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyError",
     "evalue": "'Hyperband'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/brb/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2645\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2646\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2647\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Hyperband'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-9e7ca9646905>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0msummary_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'BRBES Recommendation'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhpo_brb2bm_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrec_hpo\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0msummary_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Best HPO Technique'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaled_hpos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midxmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m     \u001b[0msummary_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Distance Value'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaled_hpos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhpo_brb2bm_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrec_hpo\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'BRBES avg. score (stdev): \\t\\t{:.3f} ({:.2f})'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnanmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbrb_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnanstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbrb_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/brb/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1767\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1768\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1769\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1770\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/brb/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1963\u001b[0m         \u001b[0;31m# fall thru to straight lookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1964\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1965\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1966\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1967\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/brb/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_label\u001b[0;34m(self, label, axis)\u001b[0m\n\u001b[1;32m    619\u001b[0m             \u001b[0;31m# but will fail when the index is not present\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m             \u001b[0;31m# see GH5667\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 621\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_xs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    622\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mIndexingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"no slices here, handle elsewhere\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/brb/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mxs\u001b[0;34m(self, key, axis, level, drop_level)\u001b[0m\n\u001b[1;32m   3535\u001b[0m             \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_level\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdrop_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3536\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3537\u001b[0;31m             \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3539\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/brb/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2646\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2647\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2648\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2649\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2650\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Hyperband'"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}